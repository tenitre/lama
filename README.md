# ğŸ§  Codebase Task Runner via Local LLM (Ollama)

A Python CLI tool that lets you analyze and process large codebases using a local LLM (via Ollama). It splits code into token-safe chunks, sends them to the LLM, and combines the responses into structured outputs like documentation or unit tests.

---

## ğŸš€ Features

- ğŸ” Scan a codebase and break files into token-safe chunks
- ğŸ§  Communicate with local LLMs via Ollama
- ğŸ“„ Generate documentation, ğŸ§ª unit tests, and âœ… TODO reports
- ğŸ§® Automatically calculate token usage and avoid overflows
- ğŸ“¦ Supports `.py`, `.cs`, `.md`, `.ipynb`, `.json`, `.yaml`, `.toml`, and `.cfg`
- ğŸ› ï¸ Extensible task engine and CLI interface
- ğŸ“š V2: Optional RAG-based codebase indexing using embeddings

---

## ğŸ“¦ Installation

```bash
# Clone this repository
git clone https://github.com/your-username/codebase-runner.git
cd codebase-runner

# Install dependencies
poetry install
```

---

## ğŸ§‘â€ğŸ’» Usage

```bash
# Basic usage
python main.py --path ./myproject --ask "Generate documentation"

# Use a specific local LLM
python main.py --path ./myproject --ask "Write unit tests" --model qwen2.5-coder
```

---

## âš™ï¸ Configuration

Define your available LLM models in `config/models.json`:

```json
{
  "default_model": "qwen2.5-coder",
  "models": {
    "qwen2.5-coder": {
      "url": "http://localhost:11434",
      "token_limit": 32000
    }
  }
}
```

---

## ğŸ“ Output

- `outputs/docs/` â†’ Markdown documentation
- `outputs/tests/` â†’ C# unit tests
- `outputs/todos/` â†’ TODO reports

---

## ğŸ›£ï¸ Roadmap

- [x] Per-file chunking and LLM interaction
- [x] Markdown and test file generation
- [x] Token-aware processing
- [ ] RAG-style indexing (V2)
- [ ] Web UI (V3)

---

## ğŸ§ª Testing

```bash
pytest tests/
```

---

## ğŸ¤ Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss your proposal.

---

## ğŸ“„ License

MIT License

---

## ğŸ™Œ Acknowledgments

- [Ollama](https://ollama.com) for local LLM orchestration
- [tiktoken](https://github.com/openai/tiktoken) for token counting
- [Nomic Embed](https://github.com/nomic-ai/nomic-embed) for vector embeddings (planned)